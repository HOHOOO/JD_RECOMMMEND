M# 排序算法

Aug 22nd

> 1.CB与UB的特性聚合（基于匹配、相似度的计算）

已知用户的特性偏好向量：$P_u=(p_1,...,p_n)$<br>
物品满足特性的程度向量：$d_i=(x_1,...,x_n)$<br>
则用户$u$对商品$d_i$的偏好得分为： $R(u,d_i)=f(x_1,...,x_n)$<br>
$f$为聚合函数，可简单理解为：<br>
用户想购买满足其所有偏好的物品，那么取完全匹配偏好的_最小值_作为用户对该商品的偏好；<br>
不需要满足全部偏好时，匹配项的_平均值_或者其他析取函数（_最大值_、_加权求和_）比较适用；<br>
当标签一致时，即为当前的 **_加权求和排序算法_**。<br>

**case1:** **直接通过 _标签词意_ 计算：**<br>

- 需要得到任意两个标签（包含商品用户）之间的相似度。特别的，当用户标签和商品标签一致时，可以直接进行计算。不一致时是否要考虑word2vec或者知识图谱来补充标签之间的关系。
- 可以计算多种相似度，甚至组合使用，作为<用户,商品>相关性的一种相对复杂的表达。

![](https://ooo.0o0.ooo/2017/08/23/599ce9db75dc0.png)

**case2:** **可以计算商品标签相似度、基于单用户历史行为计算：**<br>

- 需要计算商品之间的相似度<br>

- 需要用户有历史浏览过的商品<br>

则可以先计算得到用户之前有过行为的商品$D=(d_1,...,d_q)$<br>
$$R(u,d)=\sum\limits_ {j=1,j=i}^q {sim(d_i,d_j),R(u,dj)}$$

**case3:** **先建立商品标签到用户标签的联系，然后计算：**<br>
许多推荐系统需要从在线行为中学习偏好，而非用户显示的去表达，譬如说需要该用户之前的行为数据。<br>
则可以用之前购买过得用户进行聚合得到物品在每个偏好下的整体得分。<br>
给定一个偏好$p_j$，让$x_{ij}$ 为物品$d_i$ 满足$p_j$ 的程度， 那么分数：$w(p_j)=f(x_{1j},...,x_{nj})$<br>
so，所有的$w(p_j)$ 构成了$w_j$,参与计算$R(u,d)=f(x_1,...,x_n)$

**借鉴：**<br>

1. 将目前的标签进行聚类，分成特征比较明显的用户群体，即用户的特性偏好向量
2. 计算商品属于每个特性偏好的得分

> 2.LR&FM在点击率预估中的应用（Predicted CTR）

点击率预估，训练数据量在TB量级，特征量在亿这个量级，业内常用LR（Logistic Regression）和FM（Factorization Machines）为点击率预估建模。对LR、FM这类模型的参数学习，传统的学习算法是batch learning算法，它无法有效地处理大规模的数据集，也无法有效地处理大规模的在线数据流。这时，有效且高效的online learning算法显得尤为重要。

在计算广告系统中，一个可以携带广告请求的用户流量到达后台时，系统需要在较短时间（一般要求不超过 100ms）内返回一个或多个排序好的广告列表；在广告系统中，一般最后一步的排序 score=bid*pctralpha；其中 alpha 参数控制排序倾向，如果 alpha<1，则倾向于 pctr，否则倾向于 bid；这里的核心因子 pctr 就是通常所说的点击率（predicted click through rate）。

在推荐系统中，也有类似的需求，当用户请求到达后台的时候，我们需要返回一个排序好的文章列表或者 feeds 列表。早期的推荐系统主要以协同过滤和基于内容的推荐为主，近年来推荐系统的主流形式也变成和广告类似的两步走模式：先召回一个候选队列，然后排序；在排序这一步有很多种不同的策略，比如 pair-wise 的一些分类算法之类，但更多还是类似 facebook、youtube 之类的计算一个分数，然后排序；这个分数里往往也少不了 item 的 pctr 这个关键因子。

**_problem formulation：回归问题 vs 分类问题_**

我们可以有很多种不同的方式来定义点击问题，本文会列举两种方式；第一 种是将其看做一个分类问题；这种看法比较自然是因为我们原始的日志是曝光和点击；通过简单的归约以后，我们把点击看做正样本，曝光看做负样本的话，基于一段时间的数据样本，我们可以训练一个分类器，形式化来说，假设用户 u、物品 i，上下文 c，曝光和点击类别 e，每个样本可以看成一个

<u,i,c|e>的元组；其中 e 的取值只有 01 两种，这时候对每一个用户、物品、上下文组合<u，i，c>我们需要一个模型来对其分类，是点击还是不点击；</u，i，c></u,i,c|e>

从分类角度出发，我们有很多算法可以用，比如贝叶斯分类器；svm、最大熵等等；我们也可以使用回归算法通过阈值来处理。

另一种看法假设每个

<u,i,c>我们可以预测一个 ctr（0-1 之间的值），这时候就变成了一个回归问题，可以使用 lr、fm、神经网络等模型。</u,i,c>

在本文的结尾部分可能会有其他的一些问题定义的方法，大家也可以看到在实际业务中，不同的问题定义方式不仅决定了可以使用的模型的范围，甚至是决定了本质效果的差异。某个领域机器学习方法的进步，往往不只是模型的进步，有时候是先有问题定义的进步，然后才有模型和算法的进步；而问题定义的进步来源于我门对业务场景的理解，所以做算法的同学也一定要多花时间和精力在业务场景的分析和挖掘上。

SGD算法的迭代计算公式如下：

$\begin{equation}\mathbf{w}_{t+1} = \mathbf{w}_t - \eta_t\mathbf{g}_t\end{equation}$ formula1:
